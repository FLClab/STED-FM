{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import DataLoader \n",
    "from tqdm import tqdm \n",
    "import numpy as np\n",
    "from typing import List, Optional, Tuple\n",
    "import sys \n",
    "sys.path.insert(0, \"../../\")\n",
    "from DEFAULTS import BASE_PATH \n",
    "from loaders import get_dataset \n",
    "from model_builder import get_pretrained_model_v2 \n",
    "\n",
    "DATASET = \"dl-sim\"\n",
    "MODEL = \"mae-lightning-small\"\n",
    "WEIGHTS = \"MAE_SMALL_IMAGENET1K_V1\"\n",
    "GLOBAL_POOL = \"avg\"\n",
    "\n",
    "\n",
    "def get_classes(dataset: str):\n",
    "    if dataset == \"optim\":\n",
    "        return [\"Actin\", \"Tubulin\", \"CaMKII\", \"PSD95\"]  \n",
    "    elif dataset == \"neural-activity-states\":\n",
    "        return [\"Block\", \"0Mg\", \"GluGly\", \"48hTTX\"]\n",
    "    elif dataset == \"peroxisome\":\n",
    "        return [\"6hGluc\", \"6hMeOH\"]\n",
    "    elif dataset == \"polymer-rings\":\n",
    "        return [\"CdvB1\", \"CdvB2\"]\n",
    "    elif dataset == \"dl-sim\":\n",
    "        return [\"adhesion\", \"factin\", \"microtubule\", \"mitosis\"]\n",
    "    else:\n",
    "        raise ValueError(f\"Dataset {dataset} not supported\")\n",
    "    \n",
    "CLASSES = get_classes(DATASET)\n",
    "N_CLASSES = len(CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running on cuda ---\n",
      "mask_ratio 0.0\n",
      "pretrained True\n",
      "in_channels 3\n",
      "blocks all\n",
      "num_classes 4\n",
      "--- mae-lightning-small | Pretrained Image-Net ---\n",
      "\n",
      "--- Loaded model mae-lightning-small with ImageNet weights ---\n",
      "--- Freezing every parameter in mae-lightning-small ---\n",
      "--- Added linear probe to all frozen blocks ---\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"--- Running on {DEVICE} ---\")\n",
    "\n",
    "model, cfg = get_pretrained_model_v2(\n",
    "    name=MODEL,\n",
    "    weights=WEIGHTS,\n",
    "    path=None,\n",
    "    mask_ratio=0.0,\n",
    "    pretrained=True if \"imagenet\" in WEIGHTS.lower() else False,\n",
    "    in_channels=3 if \"imagenet\" in WEIGHTS.lower() else 1,\n",
    "    as_classifier=True,\n",
    "    blocks=\"all\",\n",
    "    num_classes=4\n",
    ")\n",
    "model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples:  DL-SIM-training.txt\n",
      "adhesion 440\n",
      "factin 623\n",
      "microtubule 725\n",
      "mitochondrial 669\n",
      "----------\n",
      "Class adhesion samples: 440\n",
      "Class factin samples: 623\n",
      "Class microtubule samples: 725\n",
      "Class mitochondrial samples: 669\n",
      "----------\n",
      "Mean: 0.2438482108613763, Std: 0.1221117670657044\n",
      "Samples:  DL-SIM-validation.txt\n",
      "adhesion 229\n",
      "factin 259\n",
      "microtubule 282\n",
      "mitochondrial 284\n",
      "----------\n",
      "Class adhesion samples: 229\n",
      "Class factin samples: 259\n",
      "Class microtubule samples: 282\n",
      "Class mitochondrial samples: 284\n",
      "----------\n",
      "Mean: 0.23256373279542203, Std: 0.12156702883520837\n",
      "Samples:  DL-SIM-testing.txt\n",
      "adhesion 99\n",
      "factin 126\n",
      "microtubule 167\n",
      "mitochondrial 135\n",
      "----------\n",
      "Class adhesion samples: 99\n",
      "Class factin samples: 126\n",
      "Class microtubule samples: 167\n",
      "Class mitochondrial samples: 135\n",
      "----------\n",
      "Mean: 0.24179844530927158, Std: 0.12182894677490595\n",
      "Training size: 5863\n",
      "Validation size: 2535\n",
      "Test size: 1242\n"
     ]
    }
   ],
   "source": [
    "_, _, test_loader = get_dataset(\n",
    "    name=DATASET,\n",
    "    transform=None,\n",
    "    training=True,\n",
    "    path=None,\n",
    "    batch_size=cfg.batch_size,\n",
    "    n_channels=3 if \"imagenet\" in WEIGHTS.lower() else 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1242, 384]) (1242,)\n"
     ]
    }
   ],
   "source": [
    "embeddings, labels, dataset_idx = [], [], []\n",
    "N = len(test_loader.dataset)\n",
    "with torch.no_grad():\n",
    "    for i in range(N):\n",
    "        img = test_loader.dataset[i][0].unsqueeze(0)\n",
    "        metadata = test_loader.dataset[i][1]\n",
    "        img = img.to(DEVICE)\n",
    "        label = metadata[\"label\"]\n",
    "        d_id = metadata[\"dataset-idx\"]\n",
    "        output = model.forward_features(img)\n",
    "        embeddings.append(output)\n",
    "        labels.append(label)\n",
    "        dataset_idx.append(d_id)\n",
    "\n",
    "embeddings = torch.cat(embeddings, dim=0)\n",
    "labels = np.array(labels)\n",
    "dataset_idx = np.array(dataset_idx)\n",
    "print(embeddings.shape, labels.shape)\n",
    "assert embeddings.shape[0] == labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1242/1242 [00:30<00:00, 40.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average retrieval accuracy: 0.88 ± 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "num_repetitions = 50\n",
    "num_samples = 30\n",
    "rep_accuracies = []\n",
    "for n in trange(embeddings.shape[0]):\n",
    "    random_embedding = embeddings[n]\n",
    "    target_label = labels[n]\n",
    "    img = test_loader.dataset[n][0].squeeze().cpu().numpy()\n",
    "    img = img[0] if \"imagenet\" in WEIGHTS.lower() else img\n",
    "    similarities = F.cosine_similarity(embeddings, random_embedding.unsqueeze(0), dim=1).cpu().numpy()\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "    query_labels = []\n",
    "\n",
    "    for i in sorted_indices[1:num_samples+1]:\n",
    "        sim = similarities[i]\n",
    "        data_index = dataset_idx[i]\n",
    "        similar_img = test_loader.dataset[data_index][0].squeeze().cpu().numpy()\n",
    "        query_labels.append(labels[i])\n",
    "        similar_img = similar_img[0] if \"imagenet\" in WEIGHTS.lower() else similar_img\n",
    "        # if labels[i] != target_label:\n",
    "        #     fig, axs = plt.subplots(1, 2)\n",
    "        #     axs[0].imshow(img, cmap='hot')\n",
    "        #     axs[1].imshow(similar_img, cmap='hot')\n",
    "        #     axs[1].set_title(f\"Similarity: {sim:.2f}\")\n",
    "        #     for ax in axs:\n",
    "        #         ax.axis('off')\n",
    "        #     plt.show()\n",
    "\n",
    "    retrieval_accuracy = np.sum(np.array(query_labels) == target_label) / len(query_labels)\n",
    "    rep_accuracies.append(retrieval_accuracy)\n",
    "\n",
    "print(f\"Average retrieval accuracy: {np.mean(rep_accuracies):.2f} ± {np.std(rep_accuracies):.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

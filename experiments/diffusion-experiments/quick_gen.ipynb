{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import torch \n",
    "import argparse \n",
    "from diffusion_models.diffusion.ddpm_lightning import DDPM  \n",
    "from diffusion_models.diffusion.denoising.unet import UNet \n",
    "from tqdm import trange, tqdm \n",
    "from torch import nn \n",
    "import os \n",
    "import sys \n",
    "sys.path.insert(0, \"../\")\n",
    "from model_builder import get_pretrained_model_v2\n",
    "from datasets import get_dataset \n",
    "\n",
    "DATASET_PATH = \"/home-local/Frederic/Datasets/FLCDataset/dataset-250k.tar\"\n",
    "MODEL = \"mae-lightning-small\"\n",
    "WEIGHTS = \"MAE_SMALL_STED\"\n",
    "CHECKPOINT = \"/home-local/Frederic/baselines/DiffusionModels/latent-guidance/MAE_SMALL_STED\"\n",
    "TIMESTEPS = 1000\n",
    "DATASET = \"STED\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_ratio 0.0\n",
      "pretrained False\n",
      "in_channels 1\n",
      "blocks all\n",
      "num_classes 4\n",
      "--- mae-lightning-small | /home-local/Frederic/baselines/mae-small_STED/pl_checkpoint-999.pth ---\n",
      "\n",
      "--- Loaded model mae-lightning-small with weights MAE_SMALL_STED ---\n",
      "--- ViT case with none-ImageNet weights or from scratch ---\n",
      "--- Freezing every parameter in mae-lightning-small ---\n",
      "--- Added linear probe to all frozen blocks ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DDPM(\n",
       "  (model): UNet(\n",
       "    (init_conv): Conv2d(1, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (time_mlp): Sequential(\n",
       "      (0): SinusoidalPosEmb()\n",
       "      (1): Linear(in_features=64, out_features=256, bias=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (label_embed): Embedding(4, 256)\n",
       "    (cond_mlp): Sequential(\n",
       "      (0): Linear(in_features=384, out_features=256, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (downs): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock(\n",
       "          (mlp): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "          (block1): Block(\n",
       "            (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Identity()\n",
       "        )\n",
       "        (2): LinearAttention(\n",
       "          (norm): RMSNorm()\n",
       "          (to_qkv): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (to_out): Sequential(\n",
       "            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Rearrange('b c (h p1) (w p2) -> b (c p1 p2) h w', p1=2, p2=2)\n",
       "          (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock(\n",
       "          (mlp): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "          (block1): Block(\n",
       "            (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Identity()\n",
       "        )\n",
       "        (2): LinearAttention(\n",
       "          (norm): RMSNorm()\n",
       "          (to_qkv): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (to_out): Sequential(\n",
       "            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Rearrange('b c (h p1) (w p2) -> b (c p1 p2) h w', p1=2, p2=2)\n",
       "          (1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock(\n",
       "          (mlp): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (block1): Block(\n",
       "            (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Identity()\n",
       "        )\n",
       "        (2): Attention(\n",
       "          (norm): RMSNorm()\n",
       "          (attend): Attend(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (to_qkv): Conv2d(128, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (to_out): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (ups): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock(\n",
       "          (mlp): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          )\n",
       "          (block1): Block(\n",
       "            (proj): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Attention(\n",
       "          (norm): RMSNorm()\n",
       "          (attend): Attend(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (to_qkv): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (to_out): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "          (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock(\n",
       "          (mlp): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (block1): Block(\n",
       "            (proj): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): LinearAttention(\n",
       "          (norm): RMSNorm()\n",
       "          (to_qkv): Conv2d(128, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (to_out): Sequential(\n",
       "            (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "          (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock(\n",
       "          (mlp): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "          (block1): Block(\n",
       "            (proj): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (block2): Block(\n",
       "            (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm): RMSNorm()\n",
       "            (act): SiLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (res_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): LinearAttention(\n",
       "          (norm): RMSNorm()\n",
       "          (to_qkv): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (to_out): Sequential(\n",
       "            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (mid_block1): ResnetBlock(\n",
       "      (mlp): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "      )\n",
       "      (block1): Block(\n",
       "        (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): RMSNorm()\n",
       "        (act): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (block2): Block(\n",
       "        (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): RMSNorm()\n",
       "        (act): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (res_conv): Identity()\n",
       "    )\n",
       "    (mid_attn): Attention(\n",
       "      (norm): RMSNorm()\n",
       "      (attend): Attend(\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (to_qkv): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (to_out): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (mid_block2): ResnetBlock(\n",
       "      (mlp): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "      )\n",
       "      (block1): Block(\n",
       "        (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): RMSNorm()\n",
       "        (act): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (block2): Block(\n",
       "        (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): RMSNorm()\n",
       "        (act): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (res_conv): Identity()\n",
       "    )\n",
       "    (final_res_block): ResnetBlock(\n",
       "      (mlp): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (block1): Block(\n",
       "        (proj): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): RMSNorm()\n",
       "        (act): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (block2): Block(\n",
       "        (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): RMSNorm()\n",
       "        (act): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (res_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (final_conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (latent_encoder): LinearProbe(\n",
       "    (backbone): VisionTransformer(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(1, 384, kernel_size=(16, 16), stride=(16, 16))\n",
       "        (norm): Identity()\n",
       "      )\n",
       "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "      (patch_drop): Identity()\n",
       "      (norm_pre): Identity()\n",
       "      (blocks): Sequential(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (3): Block(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (4): Block(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (5): Block(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (6): Block(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (7): Block(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (8): Block(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (9): Block(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (10): Block(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (11): Block(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (fc_norm): Identity()\n",
       "      (head_drop): Dropout(p=0.0, inplace=False)\n",
       "      (head): Linear(in_features=384, out_features=1000, bias=True)\n",
       "    )\n",
       "    (classification_head): Sequential(\n",
       "      (0): BatchNorm1d(384, eps=1e-06, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      (1): Linear(in_features=384, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_encoder, model_config = get_pretrained_model_v2(\n",
    "    name=MODEL,\n",
    "    weights=WEIGHTS,\n",
    "    path=None,\n",
    "    mask_ratio=0.0,\n",
    "    pretrained=False,\n",
    "    in_channels=1,\n",
    "    as_classifier=True,\n",
    "    blocks=\"all\",\n",
    "    num_classes=4,\n",
    ")\n",
    "\n",
    "denoising_model = UNet(\n",
    "    dim=64,\n",
    "    channels=1,\n",
    "    cond_dim=model_config.dim,\n",
    "    dim_mults=(1,2,4),\n",
    "    condition_type=\"latent\",\n",
    "    num_classes=4,\n",
    ")\n",
    "\n",
    "model = DDPM(\n",
    "    denoising_model=denoising_model,\n",
    "    timesteps=TIMESTEPS,\n",
    "    beta_schedule=\"linear\",\n",
    "    condition_type=\"latent\",\n",
    "    latent_encoder=latent_encoder\n",
    ")\n",
    "checkpoint = torch.load(os.path.join(CHECKPOINT, \"checkpoint-69.pth\"))\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(DATASET, DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterative sampling...: 100%|██████████| 1000/1000 [00:36<00:00, 27.08it/s]\n",
      "Iterative sampling...: 100%|██████████| 1000/1000 [00:37<00:00, 26.93it/s]\n",
      "Iterative sampling...: 100%|██████████| 1000/1000 [00:37<00:00, 26.88it/s]\n",
      "Iterative sampling...: 100%|██████████| 1000/1000 [00:37<00:00, 26.81it/s]\n",
      "Iterative sampling...: 100%|██████████| 1000/1000 [00:37<00:00, 26.73it/s]\n",
      "Iterative sampling...: 100%|██████████| 1000/1000 [00:37<00:00, 26.67it/s]\n",
      "Iterative sampling...: 100%|██████████| 1000/1000 [00:37<00:00, 26.60it/s]\n",
      "Iterative sampling...: 100%|██████████| 1000/1000 [00:37<00:00, 26.58it/s]\n",
      "Iterative sampling...: 100%|██████████| 1000/1000 [00:37<00:00, 26.53it/s]\n",
      "Iterative sampling...: 100%|██████████| 1000/1000 [00:37<00:00, 26.52it/s]\n",
      "Iterative sampling...: 100%|██████████| 1000/1000 [00:37<00:00, 26.48it/s]\n",
      "Iterative sampling...: 100%|██████████| 1000/1000 [00:37<00:00, 26.45it/s]\n",
      "Iterative sampling...: 100%|██████████| 1000/1000 [00:37<00:00, 26.43it/s]\n",
      "Iterative sampling...: 100%|██████████| 1000/1000 [00:37<00:00, 26.41it/s]\n",
      "Iterative sampling...: 100%|██████████| 1000/1000 [00:37<00:00, 26.40it/s]\n",
      "Iterative sampling...: 100%|██████████| 1000/1000 [00:37<00:00, 26.38it/s]\n",
      "Iterative sampling...: 100%|██████████| 1000/1000 [00:37<00:00, 26.35it/s]\n",
      "Iterative sampling...: 100%|██████████| 1000/1000 [00:37<00:00, 26.37it/s]\n",
      "Iterative sampling...: 100%|██████████| 1000/1000 [00:37<00:00, 26.37it/s]\n",
      "Iterative sampling...: 100%|██████████| 1000/1000 [00:37<00:00, 26.38it/s]\n",
      "100%|██████████| 20/20 [13:58<00:00, 41.90s/it]\n"
     ]
    }
   ],
   "source": [
    "N = len(dataset)\n",
    "indices = np.random.randint(0, N, size=20)\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(indices, total=len(indices)):\n",
    "        img = dataset[i]\n",
    "        img = img.unsqueeze(0).to(DEVICE)\n",
    "        condition = model.latent_encoder.forward_features(img)\n",
    "        sample = model.p_sample_loop(shape=(img.shape[0], 1, img.shape[2], img.shape[3]), cond=condition, progress=True)\n",
    "        sample = sample[:, [0], :, :].squeeze().cpu().detach().numpy()\n",
    "        img = img[:, [0], :, :].squeeze().cpu().detach().numpy()\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        axs[0].imshow(img, cmap=\"gray\")\n",
    "        axs[1].imshow(sample, cmap=\"gray\")\n",
    "        for ax in axs:\n",
    "            ax.axis(\"off\")\n",
    "        plt.subplots_adjust(left=0.01, right=0.99, top=0.99, bottom=0.01)\n",
    "        fig.savefig(f\"./quick_gens/dataset250k_{i}.pdf\", dpi=1200, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = dataset[40923]\n",
    "noisy = model.q_sample(img, torch.tensor([100]))\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.imshow(noisy.squeeze().cpu().detach().numpy(), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplots_adjust(left=0.01, right=0.99, top=0.99, bottom=0.01)\n",
    "fig.savefig(\"./quick_gens/dataset250k_noise100_40923.pdf\", dpi=1200, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

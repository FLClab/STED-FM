{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy \n",
    "import os, glob\n",
    "import tifffile\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib import colormaps\n",
    "from skimage import measure, feature\n",
    "from scipy.spatial import distance\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from wavelet import detect_spots\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from model_builder import get_pretrained_model_v2\n",
    "from utils import savefig\n",
    "\n",
    "PIXELSIZE = 0.015 # in um\n",
    "\n",
    "block_to_0mg_cmap = LinearSegmentedColormap.from_list('blockto0mg', ['fuchsia', 'dodgerblue'], N=256, gamma=1.0)\n",
    "colormaps.register(block_to_0mg_cmap, force=True)\n",
    "colormaps.register(block_to_0mg_cmap.reversed(), force=True)\n",
    "\n",
    "block_to_0mg_cmap = LinearSegmentedColormap.from_list('blocktoglugly', ['fuchsia', 'limegreen'], N=256, gamma=1.0)\n",
    "colormaps.register(block_to_0mg_cmap, force=True)\n",
    "colormaps.register(block_to_0mg_cmap.reversed(), force=True)\n",
    "\n",
    "COLORMAPS = {\n",
    "    \"0Mg\" : LinearSegmentedColormap.from_list('0mg', ['white', 'dodgerblue'], N=256, gamma=1.0),\n",
    "    \"Block\" : LinearSegmentedColormap.from_list('block', ['white', 'fuchsia'], N=256, gamma=1.0),\n",
    "    \"GluGly\" : LinearSegmentedColormap.from_list('block', ['white', 'limegreen'], N=256, gamma=1.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_encoder, model_config = get_pretrained_model_v2(\n",
    "    name=\"mae-lightning-small\",\n",
    "    weights=\"MAE_SMALL_STED\",\n",
    "    path=None,\n",
    "    mask_ratio=0.0,\n",
    "    pretrained=False,\n",
    "    in_channels=1,\n",
    "    as_classifier=True,\n",
    "    blocks=\"all\",\n",
    "    num_classes=4\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "    latent_encoder = latent_encoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmap(condition, N=None):\n",
    "    if N is None:\n",
    "        N = 256\n",
    "    if condition == \"0Mg\":\n",
    "        cmap = pyplot.get_cmap(\"blockto0mg\", N)\n",
    "    elif condition == \"Block\":\n",
    "        cmap = pyplot.get_cmap(\"blockto0mg_r\", N)\n",
    "    elif condition == \"GluGly\":\n",
    "        cmap = pyplot.get_cmap(\"blocktoglugly\", N)\n",
    "    return cmap\n",
    "\n",
    "def load_files(path):\n",
    "    files = glob.glob(path)\n",
    "    files.sort()\n",
    "    return files\n",
    "\n",
    "def extract_features(file, show=False):\n",
    "    image = tifffile.imread(file)\n",
    "    mask = detect_spots(image, J_list=[2, 3], scale_threshold=5.0)\n",
    "\n",
    "    if show:    \n",
    "        fig, axes = pyplot.subplots(1, 2)\n",
    "        axes[0].imshow(image, cmap='gray')\n",
    "        axes[1].imshow(mask, cmap='gray')\n",
    "        pyplot.show()\n",
    "\n",
    "    mask_label, num_proteins = measure.label(mask, return_num=True)\n",
    "    props = measure.regionprops(mask_label, intensity_image=image)\n",
    "    coordinates = numpy.array([p.weighted_centroid for p in props])\n",
    "\n",
    "    distances = distance.pdist(coordinates) * PIXELSIZE\n",
    "    distances = distance.squareform(distances)\n",
    "\n",
    "    image_density = num_proteins / (image.shape[0] * image.shape[1] * PIXELSIZE**2)\n",
    "    density_proteins = (numpy.sum(distances < 0.5, axis=1) - 1) / 1 # in number of proteins per um^2\n",
    "\n",
    "    features = []\n",
    "    counter = 0\n",
    "    for prop, density in zip(props, density_proteins):\n",
    "\n",
    "        img = prop.intensity_image\n",
    "        label = prop.image\n",
    "\n",
    "        min_distance = int(0.08 / PIXELSIZE) // 2 + 1 # in pixels\n",
    "        peaks = feature.peak_local_max(img, min_distance=min_distance, exclude_border=False)\n",
    "\n",
    "        if show:\n",
    "            fig, axes = pyplot.subplots(1, 2)\n",
    "            axes[0].imshow(img, cmap='gray')\n",
    "            axes[0].plot(peaks[:, 1], peaks[:, 0], 'r.')\n",
    "            axes[1].imshow(label, cmap='gray')\n",
    "            pyplot.show()\n",
    "\n",
    "        features.append([\n",
    "            prop.area,\n",
    "            prop.perimeter,\n",
    "            prop.mean_intensity,\n",
    "            prop.eccentricity,\n",
    "            prop.solidity,\n",
    "            density,\n",
    "            # len(peaks)\n",
    "        ])\n",
    "\n",
    "        # counter += 1\n",
    "        # if counter > 5:\n",
    "        #     break\n",
    "\n",
    "    return numpy.array(features)\n",
    "\n",
    "def extract_deep_features(file, show=False):\n",
    "    image = tifffile.imread(file)\n",
    "    \n",
    "    X = torch.tensor(image).unsqueeze(0).unsqueeze(0).float()\n",
    "    if torch.cuda.is_available():\n",
    "        X = X.cuda()\n",
    "    with torch.no_grad():\n",
    "        latent = latent_encoder.forward_features(X)\n",
    "        latent = latent.cpu().numpy().flatten()\n",
    "    return latent\n",
    "    \n",
    "def gen_trajectory(files, per_protein=False, extract_deep=False):\n",
    "    trajectories = defaultdict(list)\n",
    "    for file in files:\n",
    "        name = os.path.basename(file).split('.')[0].split(\"_\")[-3]\n",
    "        trajectories[name].append(file)\n",
    "    for name, files in tqdm(trajectories.items(), desc=\"Loading trajectories\"):\n",
    "\n",
    "        files = list(sorted(files, key=lambda x: int(os.path.basename(x).split('.')[0].split(\"_\")[-1])))\n",
    "\n",
    "        timesteps, features, deep_features = [], [], []\n",
    "        counter = 0\n",
    "        for file in files:\n",
    "            \n",
    "            if extract_deep:\n",
    "                deep_feature = extract_deep_features(file)\n",
    "                deep_features.append(deep_feature)\n",
    "\n",
    "            feature_per_image = extract_features(file, show=False)\n",
    "            avg_feature = numpy.mean(feature_per_image, axis=0)\n",
    "            std_feature = numpy.std(feature_per_image, axis=0)\n",
    "\n",
    "            if per_protein:\n",
    "                timesteps.extend([int(os.path.basename(file).split('.')[0].split(\"_\")[-1])] * len(feature_per_image))\n",
    "                features.extend(feature_per_image)\n",
    "            else:\n",
    "                timesteps.append(int(os.path.basename(file).split('.')[0].split(\"_\")[-1]))\n",
    "                # features.append(\n",
    "                #     numpy.concatenate([avg_feature, std_feature])\n",
    "                # )\n",
    "                features.append(\n",
    "                    avg_feature\n",
    "                )\n",
    "\n",
    "        yield name, numpy.array(deep_features), numpy.array(features), numpy.array(timesteps)\n",
    "\n",
    "        # counter += 1\n",
    "        # if counter > 5:\n",
    "        #     break        \n",
    "\n",
    "files = {\n",
    "    \"0Mg\" : load_files('./activity-experiment/examples/raw-tif/*0Mg*.tif'),\n",
    "    \"Block\" : load_files('./activity-experiment/examples/raw-tif/*Block*.tif'),\n",
    "    \"GluGly\" : load_files('./activity-block-glugly-experiment/examples/raw-tif/*GluGly*.tif'),\n",
    "}\n",
    "for key, values in files.items():\n",
    "    print(key, len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_id_per_condition, timesteps_per_condition, deep_trajectories_per_condition, trajectories_per_condition = defaultdict(list), defaultdict(list), defaultdict(list), defaultdict(list)\n",
    "for condition, files_per_condition in files.items():\n",
    "    for name, deep_features, features, steps in gen_trajectory(files_per_condition, per_protein=False, extract_deep=True):\n",
    "        trajectory_id_per_condition[condition].extend([name] * len(steps))\n",
    "        timesteps_per_condition[condition].extend(steps)\n",
    "        trajectories_per_condition[condition].append(features)\n",
    "        deep_trajectories_per_condition[condition].append(deep_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\"Area\", \"Perimeter\", \"Mean Intensity\", \"Eccentricity\", \"Solidity\", \"Density\"]\n",
    "\n",
    "for condition in files.keys():\n",
    "\n",
    "    trajectories = numpy.array(trajectories_per_condition[condition])\n",
    "    deep_trajectories = numpy.array(deep_trajectories_per_condition[condition])\n",
    "\n",
    "    # Normalize the data\n",
    "    for i in range(trajectories.shape[2]):\n",
    "        mean = numpy.mean(trajectories[:, :, i])\n",
    "        std = numpy.std(trajectories[:, :, i])\n",
    "        trajectories[:, :, i] = (trajectories[:, :, i] - mean) / std\n",
    "\n",
    "    variances = numpy.var(trajectories, axis=(0, 1))\n",
    "    sorted_idx = numpy.argsort(variances)[::-1]\n",
    "    fig, ax = pyplot.subplots()\n",
    "    cmap = get_cmap(condition, trajectories.shape[1])\n",
    "    for t in range(trajectories.shape[1]):\n",
    "        for trajectory in trajectories[:, t]:\n",
    "            ax.plot(trajectory[sorted_idx], color=cmap(t), alpha=0.25)\n",
    "    ax.set(\n",
    "        ylim=(-3, 3),\n",
    "    )\n",
    "    ax.set_xticks(\n",
    "        numpy.arange(0, len(sorted_idx), 1), labels=[FEATURES[i] for i in sorted_idx],\n",
    "        rotation=45\n",
    "    )\n",
    "    pyplot.show()\n",
    "\n",
    "    # Plots the features as a function of time\n",
    "    fig, ax = pyplot.subplots()\n",
    "    cmap = pyplot.get_cmap(\"tab10\", trajectories.shape[-1])\n",
    "    for t in range(trajectories.shape[-1]):\n",
    "        for trajectory in trajectories[:, :, t]:\n",
    "            ax.plot(trajectory, color=cmap(t), alpha=0.25)\n",
    "    ax.set(\n",
    "        ylim=(-3, 3),\n",
    "    )\n",
    "    ax.set_xticks(\n",
    "        numpy.arange(0, trajectories.shape[1], 1),\n",
    "    )\n",
    "    pyplot.show()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoldChangeScaler:\n",
    "    def __init__(self, trajectory_id, index=0):\n",
    "        self.index = index\n",
    "\n",
    "        self.baseline = None\n",
    "\n",
    "    def fit_transform(self, X, trajectory_id=None):\n",
    "        if trajectory_id is None:\n",
    "            baselines = X[:, [self.index]]\n",
    "            self.baseline = numpy.mean(baselines, axis=0, keepdims=True)\n",
    "\n",
    "            return (X - baselines) / baselines\n",
    "\n",
    "        X = X.copy()\n",
    "        baselines = []\n",
    "        for trajectory in set(trajectory_id):\n",
    "            mask = trajectory_id == trajectory\n",
    "            baseline = X[mask][[self.index], :]\n",
    "            baselines.append(baseline)\n",
    "        baseline = numpy.mean(baselines, axis=0)\n",
    "        X = (X - baseline) / baseline\n",
    "            # X[mask] = (X[mask] - baseline) / baseline\n",
    "        return X\n",
    "\n",
    "# Generate bootstrap trajectories\n",
    "def bootstrap(samples, n=1000):\n",
    "    out = []\n",
    "    for _ in range(n):\n",
    "        items = numpy.random.choice(samples, len(samples))\n",
    "        bootstrap_sample = []\n",
    "        for item in items:\n",
    "            mask = trajectory_id == item\n",
    "            bootstrap_sample.append(trajectories[mask])\n",
    "        mean = numpy.mean(bootstrap_sample, axis=0)\n",
    "\n",
    "        out.append(mean)\n",
    "    out = numpy.array(out)\n",
    "    return out\n",
    "\n",
    "def get_confidence_interval(bootstrapped_trajectory, indices, axis=0):\n",
    "    mean, cid, ciu = numpy.percentile(numpy.take(bootstrapped_trajectory, indices, axis=axis), [50, 5.0, 95], axis=0) \n",
    "    return mean, cid, ciu   \n",
    "\n",
    "def from_categorical(names):\n",
    "    unique_names = list(sorted(set(names)))\n",
    "    return numpy.array([unique_names.index(name) for name in names])\n",
    "\n",
    "def convert_timesteps(timesteps, invert=False):\n",
    "    unique_timesteps = list(sorted(set(timesteps)))\n",
    "    return numpy.array([\n",
    "        max(unique_timesteps) - unique_timesteps.index(t) if invert else unique_timesteps.index(t) for t in timesteps])\n",
    "\n",
    "def get_mask_real_images(timesteps):\n",
    "    return numpy.array([t == 0 for t in timesteps])\n",
    "\n",
    "random.seed(42)\n",
    "numpy.random.seed(42)\n",
    "\n",
    "scaled_trajectories_per_condition = {}\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "all_trajectories = numpy.concatenate([\n",
    "    trajectories_per_condition[\"0Mg\"], \n",
    "    trajectories_per_condition[\"Block\"],\n",
    "    trajectories_per_condition[\"GluGly\"]\n",
    "], axis=0)\n",
    "standard_scaler.fit(all_trajectories.reshape(-1, all_trajectories.shape[-1]))\n",
    "\n",
    "for condition in [\"0Mg\", \"Block\", \"GluGly\"]:\n",
    "\n",
    "    n = 1000\n",
    "    trajectories = numpy.array(trajectories_per_condition[condition])\n",
    "    trajectory_id = numpy.array(trajectory_id_per_condition[condition])\n",
    "\n",
    "    trajectories_ = trajectories.copy()\n",
    "\n",
    "    # Fold change scaling to plot the data\n",
    "    scaler = FoldChangeScaler(trajectory_id, index=0)\n",
    "    trajectories = scaler.fit_transform(trajectories.reshape(-1, trajectories.shape[-1]), trajectory_id=trajectory_id)\n",
    "\n",
    "    # Standardization of the data for each feature\n",
    "    # scaler = StandardScaler()\n",
    "    # trajectories = scaler.fit_transform(trajectories_.reshape(-1, trajectories_.shape[-1]))\n",
    "    scaled_trajectories_per_condition[condition] = standard_scaler.transform(trajectories_.reshape(-1, trajectories_.shape[-1]))\n",
    "\n",
    "    bootstrapped_trajectory = bootstrap(list(set(trajectory_id)), n)\n",
    "\n",
    "    variances = numpy.var(bootstrapped_trajectory, axis=(0, 1))\n",
    "    if condition == \"0Mg\":\n",
    "        sorted_idx = numpy.argsort(variances)[::-1]\n",
    "    # sorted_idx = numpy.arange(0, len(sorted_idx), 1)\n",
    "\n",
    "    fig, ax = pyplot.subplots(figsize=(4, 3))\n",
    "    cmap = get_cmap(condition, bootstrapped_trajectory.shape[1])\n",
    "    for t in range(bootstrapped_trajectory.shape[1]):\n",
    "        mean, cid, ciu = get_confidence_interval(bootstrapped_trajectory, t, axis=1)\n",
    "        # for trajectory in bootstrapped_trajectory[:, t]:\n",
    "            # ax.plot(trajectory[sorted_idx], color=cmap(t), alpha=0.1)\n",
    "        ax.plot(mean[sorted_idx], color=cmap(t))\n",
    "        ax.fill_between(\n",
    "            numpy.arange(0, bootstrapped_trajectory.shape[1], 1),\n",
    "            cid[sorted_idx], ciu[sorted_idx], color=cmap(t), alpha=0.25\n",
    "        )\n",
    "        ax.annotate(\n",
    "            f'Step {t}',\n",
    "            xy=(0.99, 1 - 0.35 * (t + 1)/bootstrapped_trajectory.shape[1]), color=cmap(t),\n",
    "            xycoords='axes fraction',\n",
    "            horizontalalignment='right'\n",
    "        )\n",
    "    ax.set(\n",
    "        ylim=(-0.5, 0.5), ylabel=\"Fold Change\", xlabel=\"Features\"\n",
    "    )\n",
    "    ax.set_xticks(\n",
    "        numpy.arange(0, len(sorted_idx), 1), labels=[FEATURES[i] for i in sorted_idx],\n",
    "        rotation=45\n",
    "    )\n",
    "    ax.annotate(\n",
    "        condition,\n",
    "        xy=(0.01, 0.99),\n",
    "        xycoords='axes fraction',\n",
    "        horizontalalignment='left',\n",
    "        verticalalignment='top'\n",
    "    )    \n",
    "    savefig(fig, \"./activity-experiment/figures/manual-features/{}_trajectory-per-feature\".format(condition), save_white=True)\n",
    "    pyplot.show()\n",
    "\n",
    "\n",
    "    fig, ax = pyplot.subplots(figsize=(4, 3))\n",
    "    cmap = pyplot.get_cmap(\"Set2\", bootstrapped_trajectory.shape[-1])\n",
    "    for t in range(bootstrapped_trajectory.shape[-1]):\n",
    "        mean, cid, ciu = get_confidence_interval(bootstrapped_trajectory, t, axis=2)\n",
    "        ax.plot(mean, color=cmap(t))\n",
    "        ax.fill_between(\n",
    "            numpy.arange(0, bootstrapped_trajectory.shape[-1], 1),\n",
    "            cid, ciu, color=cmap(t), alpha=0.25\n",
    "        )\n",
    "        # for trajectory in bootstrapped_trajectory[:, :, t]:\n",
    "        #     ax.plot(trajectory, color=cmap(t), alpha=0.1)\n",
    "        ax.annotate(\n",
    "            FEATURES[t],\n",
    "            xy=(0.01, 1 - 0.35 * (t + 1)/bootstrapped_trajectory.shape[1]), color=cmap(t),\n",
    "            xycoords='axes fraction',\n",
    "            horizontalalignment='left'\n",
    "        )\n",
    "    ax.annotate(\n",
    "        condition,\n",
    "        xy=(0.99, 0.99),\n",
    "        xycoords='axes fraction',\n",
    "        horizontalalignment='right',\n",
    "        verticalalignment='top'\n",
    "    )\n",
    "    ax.set(\n",
    "        ylim=(-0.5, 0.5), ylabel=\"Fold Change\", xlabel=\"Steps\"\n",
    "    )\n",
    "    # ax.set_xticks(\n",
    "    #     numpy.arange(0, len(sorted_idx), 1), labels=[FEATURES[i] for i in sorted_idx],\n",
    "    #     rotation=45\n",
    "    # )\n",
    "    savefig(fig, \"./activity-experiment/figures/manual-features/{}_trajectory-per-steps\".format(condition), save_white=True)\n",
    "    pyplot.show()\n",
    "\n",
    "    bootstrapped_trajectory_id = numpy.array([[f'bootstrap_{i}' for _ in range(bootstrapped_trajectory.shape[-1])] for i in range(len(bootstrapped_trajectory))]).ravel()\n",
    "    bootstrapped_timesteps = numpy.array([[i for i in range(bootstrapped_trajectory.shape[-1])] for _ in range(len(bootstrapped_trajectory))]).ravel()\n",
    "    bootstrapped_trajectory = bootstrapped_trajectory.reshape(-1, bootstrapped_trajectory.shape[-1])\n",
    "\n",
    "    # mask = bootstrapped_timesteps != 0\n",
    "    # bootstrapped_timesteps = bootstrapped_timesteps[mask]\n",
    "    # bootstrapped_trajectory = bootstrapped_trajectory[mask]\n",
    "    # bootstrapped_trajectory_id = bootstrapped_trajectory_id[mask]\n",
    "\n",
    "    # print(bootstrapped_trajectory.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phate\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "block_mask = get_mask_real_images(convert_timesteps(timesteps_per_condition[\"Block\"]))\n",
    "\n",
    "timesteps = numpy.concatenate([\n",
    "    convert_timesteps(timesteps_per_condition[\"0Mg\"]), \n",
    "    convert_timesteps(timesteps_per_condition[\"Block\"], invert=True)[block_mask],\n",
    "    convert_timesteps(timesteps_per_condition[\"GluGly\"])\n",
    "])\n",
    "mask_real_image_per_condition = {\n",
    "    \"0Mg\": get_mask_real_images(convert_timesteps(timesteps_per_condition[\"0Mg\"])),\n",
    "    \"Block\": get_mask_real_images(convert_timesteps(timesteps_per_condition[\"Block\"]))[block_mask],\n",
    "    \"GluGly\": get_mask_real_images(convert_timesteps(timesteps_per_condition[\"GluGly\"]))\n",
    "}\n",
    "mask_real_images = numpy.concatenate([\n",
    "    get_mask_real_images(convert_timesteps(timesteps_per_condition[\"0Mg\"])),\n",
    "    get_mask_real_images(convert_timesteps(timesteps_per_condition[\"Block\"]))[block_mask],\n",
    "    get_mask_real_images(convert_timesteps(timesteps_per_condition[\"GluGly\"]))\n",
    "])\n",
    "trajectories = numpy.concatenate([\n",
    "    scaled_trajectories_per_condition[\"0Mg\"], \n",
    "    scaled_trajectories_per_condition[\"Block\"][block_mask],\n",
    "    scaled_trajectories_per_condition[\"GluGly\"],\n",
    "])\n",
    "\n",
    "phate_operator = phate.PHATE()\n",
    "# embeded = phate_operator.fit_transform(bootstrapped_trajectory)\n",
    "embeded = phate_operator.fit_transform(trajectories)\n",
    "# embeded = phate_operator.fit_transform(deep_trajectories)\n",
    "\n",
    "embeded_per_condition = {\n",
    "    \"0Mg\": embeded[:len(timesteps_per_condition[\"0Mg\"])],\n",
    "    \"Block\": embeded[len(timesteps_per_condition[\"0Mg\"]): len(timesteps_per_condition[\"0Mg\"]) + sum(block_mask)],\n",
    "    \"GluGly\": embeded[len(timesteps_per_condition[\"0Mg\"]) + sum(block_mask):],\n",
    "}\n",
    "\n",
    "# pca = PCA(n_components=2)\n",
    "# embeded = pca.fit_transform(trajectories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = pyplot.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n",
    "axes[0].scatter(embeded[:, 0], embeded[:, 1], c=from_categorical(bootstrapped_trajectory_id), cmap='tab20')\n",
    "axes[1].scatter(embeded[:, 0], embeded[:, 1], c=from_categorical(bootstrapped_timesteps), cmap=\"blockto0mg\", alpha=0.25)\n",
    "xlim, ylim = axes[0].get_xlim(), axes[0].get_ylim()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pyplot.subplots(figsize=(4, 4))\n",
    "for condition in [\"0Mg\", \"Block\", \"GluGly\"]:\n",
    "\n",
    "    mask_real_images_ = mask_real_image_per_condition[condition]\n",
    "    timesteps_ = numpy.array(timesteps_per_condition[condition])\n",
    "    embeded_ = embeded_per_condition[condition]\n",
    "    if condition == \"Block\":\n",
    "        timesteps_ = timesteps_[block_mask]\n",
    "\n",
    "    ax.scatter(embeded_[~mask_real_images_, 0], embeded_[~mask_real_images_, 1], c=from_categorical(timesteps_)[~mask_real_images_], cmap=get_cmap(condition), alpha=0.3)\n",
    "    ax.scatter(embeded_[mask_real_images_, 0], embeded_[mask_real_images_, 1], color=get_cmap(condition,2)(1), edgecolors='black', zorder=10)\n",
    "xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
    "pyplot.show()\n",
    "\n",
    "vectors_per_condition = {}\n",
    "\n",
    "for condition in [\"0Mg\", \"GluGly\"]:\n",
    "    fig, ax = pyplot.subplots(1, 1, figsize=(4, 4))\n",
    "    vectors = []\n",
    "    trajectory_id = trajectory_id_per_condition[condition]\n",
    "    embeded_ = embeded_per_condition[condition]\n",
    "    for name in set(trajectory_id):\n",
    "        mask = numpy.array(trajectory_id) == name\n",
    "        start = numpy.where(mask)[0][0]\n",
    "        end = numpy.where(mask)[0][-1]\n",
    "        # ax.scatter(embeded_[start, 0], embeded_[start, 1], c='gray', alpha=0.5)\n",
    "        ax.scatter(embeded_[end, 0], embeded_[end, 1], c='gray', alpha=0.5, marker='x')\n",
    "        # ax.plot([\n",
    "        #     embeded_[start, 0],\n",
    "        #     embeded_[end, 0]\n",
    "        # ], [\n",
    "        #     embeded_[start, 1],\n",
    "        #     embeded_[end, 1]\n",
    "        # ], c='gray', alpha=0.5)\n",
    "\n",
    "        for idx in range(0, mask.sum() - 1):\n",
    "            start = numpy.where(mask)[0][idx]\n",
    "            end = numpy.where(mask)[0][-1]\n",
    "            vectors.append({\"start\" : embeded_[start, :], \"end\" : embeded_[end, :]})\n",
    "        # vectors.append({\"start\" : embeded_[start, :], \"end\" : embeded_[end, :]})\n",
    "        # ax.plot(embeded_[mask, 0], embeded_[mask, 1], alpha=0.5)\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "    pyplot.show()\n",
    "\n",
    "    vectors_per_condition[condition] = vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "num_points = 25\n",
    "XX, YY = numpy.meshgrid(numpy.linspace(xlim[0], xlim[1], num_points), numpy.linspace(ylim[0], ylim[1], num_points))\n",
    "delta_x = (xlim[1] - xlim[0]) / num_points\n",
    "delta_y = (ylim[1] - ylim[0]) / num_points\n",
    "\n",
    "def get_vectors_in_grid(vectors, x, y):\n",
    "    valid_vectors = []\n",
    "    for vector in vectors:\n",
    "        start, end = vector[\"start\"], vector[\"end\"]\n",
    "\n",
    "        distance = numpy.linalg.norm(end - start)\n",
    "        \n",
    "        fx, fy = interp1d([0, distance], [start[0], end[0]]), interp1d([0, distance], [start[1], end[1]])\n",
    "        alpha = numpy.linspace(0, distance, 5)\n",
    "        x_points, y_points = fx(alpha), fy(alpha)\n",
    "\n",
    "        for x_point, y_point in zip(x_points, y_points):\n",
    "            if x_point > x and x_point < x + delta_x and y_point > y and y_point < y + delta_y:\n",
    "                valid_vectors.append(vector)\n",
    "                break\n",
    "\n",
    "        # if (start[0] > x and start[0] < x + delta_x and start[1] > y and start[1] < y + delta_y) or \\\n",
    "        #    (end[0] > x and end[0] < x + delta_x and end[1] > y and end[1] < y + delta_y):\n",
    "        #     valid_vectors.append(vector)\n",
    "    return valid_vectors\n",
    "\n",
    "for condition in [\"0Mg\", \"GluGly\"]:\n",
    "    other_condition = \"Block\" if condition in [\"0Mg\", \"GluGly\"] else \"0Mg\"\n",
    "    vectors = vectors_per_condition[condition]\n",
    "\n",
    "    fig, ax = pyplot.subplots(1, 1, figsize=(4, 4))\n",
    "\n",
    "    # dset = numpy.array([vector[\"end\"] for vector in vectors]).T\n",
    "    dset = embeded_per_condition[condition][mask_real_image_per_condition[condition]].T\n",
    "    kernel = gaussian_kde(dset)\n",
    "\n",
    "    ZZ = numpy.reshape(kernel(numpy.vstack([XX.ravel(), YY.ravel()])), XX.shape)\n",
    "    ax.contour(XX, YY, ZZ, cmap=COLORMAPS[condition], linestyles=\"solid\", )\n",
    "\n",
    "    # for vector in vectors:\n",
    "    #     ax.plot([vector[\"start\"][0], vector[\"end\"][0]], [vector[\"start\"][1], vector[\"end\"][1]], c='gray', alpha=0.5)\n",
    "    #     # ax.scatter(vector[\"start\"][0], vector[\"start\"][1], c='gray', alpha=0.5)\n",
    "    #     ax.scatter(vector[\"end\"][0], vector[\"end\"][1], c='gray', alpha=0.5, marker=\"x\")\n",
    "    max_norm = numpy.quantile([numpy.linalg.norm(vector[\"end\"] - vector[\"start\"]) for vector in vectors], 0.95)\n",
    "    for x, y in zip(XX.ravel(), YY.ravel()):\n",
    "        vectors_in_grid = get_vectors_in_grid(vectors, x, y)\n",
    "\n",
    "        if len(vectors_in_grid) > 0:\n",
    "            avg_direction = numpy.mean([vector[\"end\"] - vector[\"start\"] for vector in vectors_in_grid], axis=0)\n",
    "            avg_direction = avg_direction #/ numpy.linalg.norm(avg_direction)\n",
    "            avg_direction = avg_direction * 1.0\n",
    "            norm = numpy.linalg.norm(avg_direction)\n",
    "            ax.quiver(x + delta_x / 2, y + delta_y / 2, avg_direction[0], avg_direction[1], color='black', scale=1)#, alpha=min(1, (norm)/max_norm))\n",
    "\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.set(\n",
    "        xlabel=\"PHATE 1\", xticklabels=[],\n",
    "        ylabel=\"PHATE 2\", yticklabels=[],\n",
    "    )\n",
    "    # ax.set_title(f\"{other_condition} to {condition}\")\n",
    "    savefig(fig, f\"./activity-experiment/figures/manual-features/{other_condition}_to_{condition}_vector-field\", save_white=True)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "\n",
    "for condition in [\"0Mg\", \"GluGly\"]:\n",
    "\n",
    "    deep_trajectories = numpy.array(deep_trajectories_per_condition[condition])\n",
    "    deep_trajectories = deep_trajectories.reshape(-1, deep_trajectories.shape[-1])\n",
    "\n",
    "    unique_names = list(sorted(set(trajectory_id_per_condition[condition])))\n",
    "    trajectory_id = numpy.array([unique_names.index(name) for name in trajectory_id_per_condition[condition]])\n",
    "\n",
    "    unique_names = list(sorted(set(timesteps_per_condition[condition])))\n",
    "    timesteps = numpy.array([unique_names.index(name) for name in timesteps_per_condition[condition]])\n",
    "\n",
    "    real_image = mask_real_image_per_condition[condition]\n",
    "    \n",
    "    D = deep_trajectories\n",
    "    D = StandardScaler().fit_transform(D)\n",
    "\n",
    "    Y = hierarchy.linkage(D, method=\"average\", metric=\"cosine\")\n",
    "    Y2 = hierarchy.linkage(D.T, method=\"average\", metric=\"cosine\")\n",
    "    # ind = hierarchy.fcluster(Y, dendrogram_distance, 'distance')  \n",
    "\n",
    "    fig = pyplot.figure(figsize=(5, 5))\n",
    "\n",
    "    ax3 = fig.add_axes([0,0,0.1,1.0])\n",
    "    ax3.set_xticks([])\n",
    "    ax3.set_yticks([])\n",
    "    fig.gca().invert_yaxis() # this plus the y-axis invert in the heatmap flips the y-axis heatmap orientation\n",
    "    ax3.axis('off')    \n",
    "\n",
    "    Z1 = hierarchy.dendrogram(\n",
    "        Y, orientation='left',\n",
    "        color_threshold=0.75, \n",
    "        above_threshold_color=\"silver\",\n",
    "        ax=ax3\n",
    "    )    \n",
    "    Z2 = hierarchy.dendrogram(\n",
    "        Y2, orientation='left',\n",
    "        color_threshold=0.75, \n",
    "        above_threshold_color=\"silver\",\n",
    "        no_plot=True\n",
    "    )        \n",
    "    for collection in ax3.collections:\n",
    "        collection.set_linewidth(0.5)\n",
    "\n",
    "    ax4 = fig.add_axes([0.1,0,0.02,1.0])\n",
    "    ax4.set_xticks([])\n",
    "    ax4.set_yticks([])\n",
    "    ax4.axis('off')\n",
    "    cmap = pyplot.get_cmap(\"Blues\", len(set(timesteps)) + 1)\n",
    "    for i, leaf in enumerate(Z1[\"leaves\"]):\n",
    "        ax4.barh(i + 0.5, 1, 1.0, color=cmap(timesteps[leaf] + 1))\n",
    "    #     # ax4.axhline(i + 0.5, color=cmap(GROUPS_MODEL[groups[leaf]] + 1))\n",
    "    ax4.set(\n",
    "        ylim=(0, len(Z1[\"leaves\"])), xlim=(0, 1)\n",
    "    )\n",
    "    ax4.invert_yaxis()\n",
    "\n",
    "    ax5 = fig.add_axes([0.12,0,0.02,1.0])\n",
    "    ax5.set_xticks([])\n",
    "    ax5.set_yticks([])\n",
    "    ax5.axis('off')\n",
    "    cmap = pyplot.get_cmap(COLORMAPS[condition], len(set(real_image)) + 1)\n",
    "    cmap = COLORMAPS[condition]\n",
    "    for i, leaf in enumerate(Z1[\"leaves\"]):\n",
    "        ax5.barh(i + 0.5, 1, 1.0, color=cmap((real_image[leaf] + 1) / (len(set(real_image)) + 1)))\n",
    "        # ax4.axhline(i + 0.5, color=cmap(GROUPS_ROUTINE[groups[leaf]] + 1))\n",
    "    ax5.set(\n",
    "        ylim=(0, len(Z1[\"leaves\"])), xlim=(0, 1)\n",
    "    )\n",
    "    ax5.invert_yaxis()        \n",
    "\n",
    "    axmatrix2 = fig.add_axes([0.15,0,0.85, 1.0])\n",
    "    idx1 = Z1['leaves']\n",
    "    idx2 = Z2['leaves']\n",
    "\n",
    "    sorted_co_matrix = D[idx1,:]\n",
    "    sorted_co_matrix = sorted_co_matrix[:,idx2]\n",
    "    im2 = axmatrix2.matshow(sorted_co_matrix, aspect='equal', origin='lower', cmap=\"coolwarm\", vmin=-2, vmax=2)\n",
    "    axmatrix2.set_xticks([])\n",
    "    axmatrix2.set_yticks([])\n",
    "    # fig.gca().invert_yaxis() # this plus the x-axis invert in the right-flipped dendrogram flips the y-axis\n",
    "\n",
    "    # num_cluster = ind.max().item()    \n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "matrices = {}\n",
    "all_silhouettes = []\n",
    "all_elbows = []\n",
    "\n",
    "all_timesteps = []\n",
    "all_trajectories = []\n",
    "for condition in [\"0Mg\", \"GluGly\"]:\n",
    "\n",
    "    deep_trajectories = numpy.array(deep_trajectories_per_condition[condition])\n",
    "    deep_trajectories = deep_trajectories.reshape(-1, deep_trajectories.shape[-1])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    deep_trajectories = scaler.fit_transform(deep_trajectories)\n",
    "\n",
    "    unique_names = list(sorted(set(trajectory_id_per_condition[condition])))\n",
    "    trajectory_id = numpy.array([unique_names.index(name) for name in trajectory_id_per_condition[condition]])\n",
    "\n",
    "    unique_names = list(sorted(set(timesteps_per_condition[condition])))\n",
    "    timesteps = numpy.array([unique_names.index(name) for name in timesteps_per_condition[condition]])\n",
    "    \n",
    "    all_timesteps.extend(timesteps)\n",
    "    all_trajectories.extend(deep_trajectories)\n",
    "\n",
    "    # deep_trajectories = numpy.array(all_trajectories)\n",
    "    # timesteps = numpy.array(all_timesteps)\n",
    "\n",
    "    n_clusters = 25\n",
    "    #     n_clusters = min(50, n_clusters)\n",
    "    cluster_matrix = numpy.zeros((len(deep_trajectories), len(deep_trajectories)))\n",
    "    silhouettes = []\n",
    "    elbows = []\n",
    "    for n in range(2, n_clusters):\n",
    "        kmeans = KMeans(n_clusters=n, random_state=42, n_init=\"auto\").fit(deep_trajectories)\n",
    "\n",
    "        klabels = kmeans.labels_\n",
    "        for j in range(len(deep_trajectories)):\n",
    "            for i in range(j, len(deep_trajectories)):\n",
    "    #                 if j == i:\n",
    "    #                     continue                    \n",
    "                if klabels[j] == klabels[i]:\n",
    "                    cluster_matrix[j, i] += 1\n",
    "                    cluster_matrix[i, j] += 1   \n",
    "                    \n",
    "        silhouettes.append(silhouette_score(deep_trajectories, klabels, metric=\"euclidean\"))\n",
    "        elbows.append(kmeans.inertia_)\n",
    "    matrices[condition] = cluster_matrix / n_clusters\n",
    "    all_silhouettes.append(silhouettes)\n",
    "    all_elbows.append(elbows)\n",
    "\n",
    "for silhouette, elbow in zip(all_silhouettes, all_elbows):\n",
    "    fig, axes = pyplot.subplots(1, 2, figsize=(8, 4))\n",
    "    axes[0].plot(numpy.arange(2, 2 + len(silhouette)), silhouette)\n",
    "    axes[0].set_title(\"Silhouette Score\")\n",
    "\n",
    "    axes[1].plot(numpy.arange(2, 2 + len(elbow)), elbow)\n",
    "    axes[1].set_title(\"Elbow Score\")\n",
    "\n",
    "    pyplot.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "CLUSTERS = {\n",
    "    \"0Mg\" : 10,\n",
    "    \"Block\" : 8\n",
    "}\n",
    "SCALE = 0.8\n",
    "\n",
    "deep_trajectories_real_images = []\n",
    "for condition in [\"0Mg\", \"GluGly\"]:\n",
    "    deep_trajectories = numpy.array(deep_trajectories_per_condition[condition])\n",
    "    deep_trajectories = deep_trajectories.reshape(-1, deep_trajectories.shape[-1])\n",
    "\n",
    "    mask = mask_real_image_per_condition[condition]\n",
    "    deep_trajectories_real_images.append(deep_trajectories[mask])\n",
    "    \n",
    "deep_trajectories_real_images = numpy.concatenate(deep_trajectories_real_images)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "deep_trajectories_real_images = scaler.fit_transform(deep_trajectories_real_images)\n",
    "\n",
    "silhouettes = []\n",
    "n_clusters = 15\n",
    "for n in range(2, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n, random_state=42, n_init=\"auto\").fit(deep_trajectories_real_images)\n",
    "    klabels = kmeans.labels_\n",
    "    silhouettes.append(silhouette_score(deep_trajectories_real_images, klabels, metric=\"euclidean\"))\n",
    "\n",
    "fig, ax = pyplot.subplots(1, 1, figsize=(4, 4))\n",
    "ax.plot(numpy.arange(2, 2 + len(silhouettes)), silhouettes)\n",
    "ax.set_title(\"Silhouette Score\")\n",
    "pyplot.show()\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=42, n_init=\"auto\").fit(deep_trajectories_real_images)\n",
    "\n",
    "clusters_per_condition = {}\n",
    "\n",
    "for condition in [\"0Mg\", \"GluGly\"]:\n",
    "\n",
    "    deep_trajectories = numpy.array(deep_trajectories_per_condition[condition])\n",
    "    deep_trajectories = deep_trajectories.reshape(-1, deep_trajectories.shape[-1])\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    deep_trajectories = scaler.transform(deep_trajectories)\n",
    "\n",
    "    unique_names = list(sorted(set(timesteps_per_condition[condition])))\n",
    "    # unique_names = numpy.unique(timesteps)\n",
    "    print(unique_names)\n",
    "    timesteps = numpy.array([unique_names.index(name) for name in timesteps_per_condition[condition]])\n",
    "    timesteps = convert_timesteps(timesteps, invert=condition == \"Block\")\n",
    "\n",
    "    # fig, ax = pyplot.subplots(1, 1, figsize=(4, 4))\n",
    "    # im = ax.matshow(correlation_matrix, cmap=\"magma\", vmin=0, vmax=1)\n",
    "    # pyplot.show()\n",
    "\n",
    "    D = matrices[condition]\n",
    "\n",
    "    distances = distance.cdist(D, D)\n",
    "    mask = numpy.triu(numpy.ones_like(distances, dtype=bool)) * numpy.invert(numpy.eye(len(distances), dtype=bool))\n",
    "    dendrogram_distance = numpy.quantile(distances[mask], q=0.25)  \n",
    "    print(dendrogram_distance)  \n",
    "\n",
    "    Y = hierarchy.linkage(D, method=\"average\", metric=\"euclidean\")\n",
    "    Y2 = hierarchy.linkage(D.T, method=\"average\", metric=\"euclidean\")\n",
    "\n",
    "    # labels = hierarchy.fcluster(Y, CLUSTERS[condition], 'maxclust')\n",
    "    labels = hierarchy.fcluster(Y, dendrogram_distance, 'distance')\n",
    "    clusters_per_condition[condition] = labels\n",
    "\n",
    "    # dendrogram_distance = sorted(Y[:, 2])[-1 * CLUSTERS[condition] + 1]\n",
    "\n",
    "    fig = pyplot.figure(figsize=(5, 5))\n",
    "\n",
    "    ax3 = fig.add_axes([0,0,0.1,SCALE])\n",
    "    ax3.set_xticks([])\n",
    "    ax3.set_yticks([])\n",
    "    fig.gca().invert_yaxis() # this plus the y-axis invert in the heatmap flips the y-axis heatmap orientation\n",
    "    ax3.axis('off')    \n",
    "\n",
    "    cmap = pyplot.get_cmap(\"Grays\", (labels.max()).item()+1)\n",
    "    hierarchy.set_link_color_palette([matplotlib.colors.to_hex(cmap(i+1)) for i in range(labels.max())])\n",
    "    Z1 = hierarchy.dendrogram(\n",
    "        Y, orientation='left',\n",
    "        color_threshold=dendrogram_distance, \n",
    "        above_threshold_color=\"silver\",\n",
    "        ax=ax3\n",
    "    )    \n",
    "    Z2 = hierarchy.dendrogram(\n",
    "        Y2, orientation='left',\n",
    "        color_threshold=dendrogram_distance, \n",
    "        above_threshold_color=\"silver\",\n",
    "        no_plot=True\n",
    "    )        \n",
    "    for collection in ax3.collections:\n",
    "        collection.set_linewidth(0.5)\n",
    "\n",
    "    ax4 = fig.add_axes([0.1,0,0.04,SCALE])\n",
    "    ax4.set_xticks([])\n",
    "    ax4.set_yticks([])\n",
    "    ax4.axis('off')\n",
    "    # cmap = pyplot.get_cmap(\"Blues\", len(set(timesteps)) + 1)\n",
    "    cmap = get_cmap(condition, len(set(timesteps)) + 1)\n",
    "    for i, leaf in enumerate(Z1[\"leaves\"]):\n",
    "        ax4.barh(i + 0.5, 1, 1.0, color=cmap(timesteps[leaf] + 1))\n",
    "        # ax4.axhline(i + 0.5, color=cmap(GROUPS_MODEL[groups[leaf]] + 1))\n",
    "    ax4.set(\n",
    "        ylim=(0, len(Z1[\"leaves\"])), xlim=(0, 1)\n",
    "    )\n",
    "    ax4.invert_yaxis()\n",
    "\n",
    "    # ax5 = fig.add_axes([0.12,0,0.02,1.0])\n",
    "    # ax5.set_xticks([])\n",
    "    # ax5.set_yticks([])\n",
    "    # ax5.axis('off')\n",
    "    # cmap = pyplot.get_cmap(\"Purples\", len(set(trajectory_id)) + 1)\n",
    "    # for i, leaf in enumerate(Z1[\"leaves\"]):\n",
    "    #     ax5.barh(i + 0.5, 1, 1.0, color=cmap(trajectory_id[leaf] + 1))\n",
    "    #     # ax4.axhline(i + 0.5, color=cmap(GROUPS_ROUTINE[groups[leaf]] + 1))\n",
    "    # ax5.set(\n",
    "    #     ylim=(0, len(Z1[\"leaves\"])), xlim=(0, 1)\n",
    "    # )\n",
    "    # ax5.invert_yaxis()        \n",
    "\n",
    "    axmatrix2 = fig.add_axes([0.15,0,0.85, SCALE])\n",
    "    idx1 = Z1['leaves']\n",
    "    idx2 = Z2['leaves']\n",
    "\n",
    "    sorted_co_matrix = D[idx1,:]\n",
    "    sorted_co_matrix = sorted_co_matrix[:,idx2]\n",
    "    im2 = axmatrix2.matshow(sorted_co_matrix, aspect='equal', origin='lower', cmap=\"Purples\", vmin=0, vmax=0.5)\n",
    "    axmatrix2.set_xticks([])\n",
    "    axmatrix2.set_yticks([])\n",
    "    # fig.gca().invert_yaxis() # this plus the x-axis invert in the right-flipped dendrogram flips the y-axis\n",
    "    fig.gca().invert_xaxis() # this plus the x-axis invert in the right-flipped dendrogram flips the y-axis\n",
    "\n",
    "    savefig(fig, f\"./activity-experiment/figures/deep-features/{condition}_dendrogram\", save_white=True)\n",
    "\n",
    "    #  num_cluster = ind.max().item()    \n",
    "    uniques = numpy.unique(labels)\n",
    "\n",
    "    # if condition == \"0Mg\":\n",
    "    #     kmeans = KMeans(n_clusters=CLUSTERS[condition], random_state=42, n_init=\"auto\").fit(deep_trajectories)\n",
    "    #     labels = kmeans.labels_\n",
    "    # else:\n",
    "    # labels = kmeans.predict(deep_trajectories)\n",
    "    # uniques = numpy.arange(0, kmeans.n_clusters)\n",
    "\n",
    "    proportions = numpy.zeros((len(unique_names), len(uniques)))\n",
    "    for i, unique in enumerate(uniques):\n",
    "        mask = labels == unique\n",
    "        \n",
    "        timestep, counts = numpy.unique(timesteps[mask], return_counts=True)\n",
    "        for t, c in zip(timestep, counts):\n",
    "            proportions[t, i] = c\n",
    "    \n",
    "    proportions = proportions / numpy.sum(proportions, axis=1, keepdims=True)\n",
    "\n",
    "    fig, ax = pyplot.subplots(figsize=(10, 5))\n",
    "    ax.imshow(proportions, vmin=0, vmax=0.5, cmap=\"Purples\")\n",
    "    for j in range(proportions.shape[1]):\n",
    "        for i in range(proportions.shape[0]):\n",
    "            ax.text(j, i, f'{proportions[i, j]:.2f}', ha='center', va='center', color='black')\n",
    "    ax.set(\n",
    "        xlabel=\"Clusters\", ylabel=\"Steps\"\n",
    "    )\n",
    "    savefig(fig, f\"./activity-experiment/figures/deep-features/{condition}_proportion-per-steps\", save_white=True)\n",
    "    pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity between clusters\n",
    "from scipy.spatial import distance\n",
    "from itertools import combinations\n",
    "\n",
    "all_deep_trajectories = []\n",
    "for condition in [\"0Mg\", \"GluGly\"]:\n",
    "    deep_trajectories = numpy.array(deep_trajectories_per_condition[condition])\n",
    "    deep_trajectories = deep_trajectories.reshape(-1, deep_trajectories.shape[-1])\n",
    "\n",
    "    all_deep_trajectories.extend(deep_trajectories)\n",
    "\n",
    "all_deep_trajectories = numpy.array(all_deep_trajectories)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(all_deep_trajectories)\n",
    "\n",
    "deep_feature_per_condition = []\n",
    "for condition, labels in clusters_per_condition.items():\n",
    "    \n",
    "    deep_trajectories = numpy.array(deep_trajectories_per_condition[condition])\n",
    "    deep_trajectories = deep_trajectories.reshape(-1, deep_trajectories.shape[-1])\n",
    "    deep_trajectories = scaler.transform(deep_trajectories)\n",
    "\n",
    "    deep_trajectories_per_cluster = []\n",
    "    for unique in numpy.unique(labels):\n",
    "        mask = labels == unique\n",
    "        deep_trajectories_per_cluster.append(deep_trajectories[mask])\n",
    "    \n",
    "    deep_feature_per_condition.append(deep_trajectories_per_cluster)\n",
    "\n",
    "conditions = list(clusters_per_condition.keys())\n",
    "for i, j in combinations(range(len(deep_feature_per_condition)), 2):\n",
    "    deep_features_1 = deep_feature_per_condition[i]\n",
    "    centroids = [numpy.mean(df, axis=0) for df in deep_features_1]\n",
    "    \n",
    "    deep_features_2 = deep_feature_per_condition[j]\n",
    "\n",
    "    cluster_ids = []\n",
    "    for c, df in enumerate(deep_features_2):\n",
    "        cluster_ids.extend([c] * len(df))\n",
    "    flattened_deep_features_2 = numpy.concatenate(deep_features_2, axis=0)\n",
    "    \n",
    "    distances = distance.cdist(centroids, flattened_deep_features_2, metric=\"euclidean\")\n",
    "    print(distances.shape)\n",
    "    associated_cluster = numpy.argmin(distances, axis=0)\n",
    "\n",
    "    proportions = numpy.zeros((len(deep_features_1), len(deep_features_2)))\n",
    "    for associated, cids in zip(associated_cluster, cluster_ids):\n",
    "        proportions[associated, cids] += 1\n",
    "    proportions = proportions / numpy.sum(proportions, axis=0, keepdims=True)\n",
    "    \n",
    "    fig, ax = pyplot.subplots(figsize=(4, 4))\n",
    "    im = ax.imshow(proportions, cmap=\"Purples\", vmin=0, vmax=1)\n",
    "    pyplot.colorbar(im, ax=ax)\n",
    "    ax.set(\n",
    "        xlabel=f\"Clusters {conditions[j]}\", ylabel=f\"Clusters {conditions[i]}\",\n",
    "        xticks=numpy.arange(0, proportions.shape[1], 1), yticks=numpy.arange(0, proportions.shape[0], 1)\n",
    "    )\n",
    "    for pj in range(proportions.shape[1]):\n",
    "        for pi in range(proportions.shape[0]):\n",
    "            ax.text(pj, pi, f'{proportions[pi, pj]:.2f}', ha='center', va='center', color='black')\n",
    "\n",
    "    savefig(fig, f\"./activity-experiment/figures/deep-features/cluster-association_{conditions[j]}-{conditions[i]}\", save_white=True)\n",
    "    pyplot.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "class MaskedStandardScaler:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.mean = None \n",
    "        self.std = None\n",
    "\n",
    "    def fit_transform(self, X, mask):\n",
    "        self.fit(X, mask)\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def fit(self, X, mask):\n",
    "        self.mean = numpy.mean(X, axis=0, keepdims=True)\n",
    "        self.std = numpy.std(X, axis=0, keepdims=True)\n",
    "\n",
    "        mask = numpy.array(mask)\n",
    "        self.mean[:, ~mask] = 0\n",
    "        self.std[:, ~mask] = 1\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.mean is None or self.std is None:\n",
    "            raise ValueError(\"Scaler has not been fitted yet\")\n",
    "        X = (X - self.mean) / self.std\n",
    "        return X\n",
    "\n",
    "all_trajectories = []\n",
    "for condition, labels in clusters_per_condition.items():\n",
    "    trajectories = numpy.array(trajectories_per_condition[condition])\n",
    "    trajectories = trajectories.reshape(-1, trajectories.shape[-1])\n",
    "    all_trajectories.append(trajectories)\n",
    "all_trajectories = numpy.concatenate(all_trajectories, axis=0)\n",
    "\n",
    "scaler = MaskedStandardScaler()\n",
    "scaler.fit(all_trajectories, [True, True, True, False, False, True])\n",
    "\n",
    "for condition, labels in clusters_per_condition.items():\n",
    "    \n",
    "    trajectories = numpy.array(trajectories_per_condition[condition])\n",
    "    trajectories = trajectories.reshape(-1, trajectories.shape[-1])\n",
    "    trajectories = scaler.transform(trajectories)\n",
    "\n",
    "    deep_trajectories = numpy.array(deep_trajectories_per_condition[condition])\n",
    "    deep_trajectories = deep_trajectories.reshape(-1, deep_trajectories.shape[-1])\n",
    "\n",
    "    unique_labels = numpy.unique(labels)\n",
    "    correlation_matrix = numpy.zeros((len(unique_labels), trajectories.shape[-1]))\n",
    "    for i, cluster_id in enumerate(unique_labels):\n",
    "        mask = labels == cluster_id\n",
    "\n",
    "        d_traj = deep_trajectories[mask]\n",
    "        t_traj = trajectories[mask]\n",
    "\n",
    "        for feature_idx in range(t_traj.shape[-1]):\n",
    "            \n",
    "            # clf = Ridge(random_state=42)\n",
    "            # clf.fit(d_traj, t_traj[:, feature_idx])\n",
    "            # score = clf.score(d_traj, t_traj[:, feature_idx])\n",
    "            # print(score)\n",
    "            correlation_matrix[i, feature_idx] = numpy.mean(t_traj[:, feature_idx])\n",
    "\n",
    "    fig, ax = pyplot.subplots(figsize=(4, 4))\n",
    "    ax.imshow(correlation_matrix, cmap=\"Purples\")\n",
    "    ax.set(\n",
    "        ylabel=\"Clusters\",\n",
    "    )\n",
    "    ax.set_xticks(\n",
    "        numpy.arange(0, trajectories.shape[-1], 1), labels=[FEATURES[i] for i in range(trajectories.shape[-1])],\n",
    "        rotation=45\n",
    "    )\n",
    "    savefig(fig, f\"./activity-experiment/figures/deep-features/{condition}_manual-features-per-cluster\", save_white=True)\n",
    "    pyplot.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
